{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expected-product",
   "metadata": {},
   "source": [
    "# JEC profile plots\n",
    "\n",
    "Simple mix of https://github.com/cms-jet/CoffeaJERC/blob/master/genL2L3.ipynb and [nanoevents.ipynb](https://github.com/CoffeaTeam/coffea/blob/master/binder/nanoevents.ipynb) to illustrate profile plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "import time\n",
    "from coffea.nanoevents.methods import candidate\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0b7e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.behavior.update(candidate.behavior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aa5693",
   "metadata": {},
   "source": [
    "### Decide whether to load filesets from a json file or enter individual root files\n",
    "Set `LoadJSONfiles` to `True` to import filesets with several root files from a given .json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23faaffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LoadJSONfiles = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e565ad9",
   "metadata": {},
   "source": [
    "### Change to your xrootd username, unless you're AC Williams ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358820a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrootdstr = 'root://acwillia@cmsxrootd.fnal.gov/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "filesets = {}\n",
    "\n",
    "if not LoadJSONfiles:\n",
    "    fname = xrootdstr + \"/store/mc/RunIISummer19UL17NanoAOD/QCD_Pt-15to7000_TuneCP5_Flat2018_13TeV_pythia8/NANOAODSIM/JMECustomTuples_106X_mc2017_realistic_v6-v1/280000/0F7E67F1-5FCB-EC4B-A0B3-E0E9B98AFC43.root\"\n",
    "    #events = NanoEventsFactory.from_root(fname, schemaclass=NanoAODSchema).events()\n",
    "    \n",
    "    filesets = {\n",
    "        \"QCDFlat\": [fname]\n",
    "    }\n",
    "    \n",
    "else:\n",
    "    import json\n",
    "    json_samples = json.load( open('samples_qcdflat.json') )\n",
    "    \n",
    "    for sample in json_samples[\"samples\"]:    \n",
    "        name, xsec, nevents, files = sample['name'], sample['xsec'], sample['nevents'], sample['files']\n",
    "        for ifile,file in enumerate(files):\n",
    "            files[ifile] = xrootdstr + file\n",
    "        filesets[name] = files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e8922",
   "metadata": {},
   "source": [
    "### Define the processor, or import one from a separate `.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea import processor, hist\n",
    "class FancyJECL2L3Processor(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        dataset_axis = hist.Cat(\"dataset\", \"Primary dataset\")\n",
    "        eta_axis = hist.Bin(\"eta\", r\"$\\eta$\", 20, -5, 5)\n",
    "        pt_axis = hist.Bin(\"pt\", r\"$p_{T}$ [GeV]\", \n",
    "                           np.array([5,10,15,20,25,30,35,40,45,50,60,70,80,90,\n",
    "                                     100,120,140,160,180,\n",
    "                                     200,250,300,350,400,450,500,\n",
    "                                     600,700,800,900,1000,\n",
    "                                     1500,2000,3000,4000,5000]))\n",
    "        dr_axis = hist.Bin(\"dr\", r\"$\\delta (\\eta)$\", 20, 0., 1)\n",
    "        m_axis = hist.Bin(\"m\", r\"$p_{T}$ [GeV]\", 200, 0, 500)\n",
    "        r_axis = hist.Bin(\"r\", \"RECO / GEN response\", 200, 0, 5)\n",
    "        \n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'pt':hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            'eta':hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            'dr':hist.Hist(\"Counts\", dataset_axis, dr_axis),\n",
    "            'r_pt_ptveta':hist.Hist(\"Counts\", dataset_axis, pt_axis, eta_axis, r_axis),\n",
    "            'r_m_ptveta':hist.Hist(\"Counts\", dataset_axis, pt_axis, eta_axis, r_axis),\n",
    "            'r_m_ptvm':hist.Hist(\"Counts\", dataset_axis, pt_axis, m_axis, r_axis),\n",
    "            'cutflow': processor.defaultdict_accumulator(int),\n",
    "        })\n",
    "    \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "    \n",
    "    def process(self, events):\n",
    "        output = self.accumulator.identity()\n",
    "        output['cutflow']['all events'] += len(events)\n",
    "        #print(len(events))\n",
    "            \n",
    "        selectedEvents = events[\n",
    "            (ak.num(events.Jet) > 2)\n",
    "        ]\n",
    "\n",
    "        jet = selectedEvents.Jet[:,0:2]\n",
    "        jet = ak.flatten(jet)\n",
    "        \n",
    "        # --- only with genmatch --- #\n",
    "        jet = jet[~ak.is_none(jet.matched_gen)]\n",
    "        \n",
    "        # --- only with good deltaR match --- #\n",
    "        jet = jet[jet.delta_r(jet.matched_gen)<0.2]\n",
    "        \n",
    "        ptresponse = jet.pt/jet.matched_gen.pt\n",
    "        \n",
    "        output['dr'].fill(dataset=selectedEvents.metadata[\"dataset\"],\n",
    "                            dr=jet.delta_r(jet.matched_gen))\n",
    "        output['pt'].fill(dataset=selectedEvents.metadata[\"dataset\"],\n",
    "                            pt=jet.pt)\n",
    "        output['eta'].fill(dataset=selectedEvents.metadata[\"dataset\"], \n",
    "                                 eta=jet.eta)\n",
    "        output['r_pt_ptveta'].fill( dataset=selectedEvents.metadata[\"dataset\"], pt=jet.pt, eta=jet.eta, r=ptresponse)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e1ffdb",
   "metadata": {},
   "source": [
    "### Try the experimental dask processor\n",
    "\n",
    "If you'd like ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5736a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "UsingDaskExecutor = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "if UsingDaskExecutor == True:\n",
    "    from dask.distributed import Client\n",
    "    from lpcjobqueue import LPCCondorCluster\n",
    "    if __name__ == \"__main__\":\n",
    "        tic = time.time()\n",
    "        cluster = LPCCondorCluster()\n",
    "        # minimum > 0: https://github.com/CoffeaTeam/coffea/issues/465\n",
    "        cluster.adapt(minimum=1, maximum=10)\n",
    "        client = Client(cluster)\n",
    "        #client.upload_file('FancyJECL2L3Processor.py')\n",
    "        \n",
    "    tstart = time.time() \n",
    "    output = processor.run_uproot_job(\n",
    "        filesets,\n",
    "        treename           = \"Events\",\n",
    "        processor_instance = FancyJECL2L3Processor(),\n",
    "        executor           = processor.dask_executor,\n",
    "        executor_args      = {\"client\": client, \n",
    "                              \"schema\": NanoAODSchema},\n",
    "    )\n",
    "    elapsed = time.time() - tstart\n",
    "    print(output)\n",
    "    print(\"Total time from dask: \", elapsed)\n",
    "    print()\n",
    "    print(\"Events/s:\", output['cutflow']['all events']/elapsed)\n",
    "    \n",
    "else: #Just use iterative executor\n",
    "    tstart = time.time() \n",
    "    output = processor.run_uproot_job(\n",
    "        filesets,\n",
    "        treename           = \"Events\",\n",
    "        processor_instance = FancyJECL2L3Processor(),\n",
    "        executor           = processor.iterative_executor,\n",
    "        executor_args      = {\"schema\": NanoAODSchema},\n",
    "    )\n",
    "    elapsed = time.time() - tstart\n",
    "    print(output)\n",
    "    print(\"Total time from iterative executor: \", elapsed)\n",
    "    print()\n",
    "    print(\"Events/s: \", output['cutflow']['all events']/elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as sciop\n",
    "import scipy.special as scisp \n",
    "#import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-stack",
   "metadata": {},
   "source": [
    "### Define the Fit Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GammaFit(x, alpha, beta, amp):\n",
    "    return ( amp * beta**(alpha) * x**(alpha-1) * np.exp(-beta*x) / scisp.gamma(alpha) )\n",
    "\n",
    "def GaussianFit1(x, xbar, A, sigma):\n",
    "    return ( A * np.exp(-0.5*(x - xbar)**2/sigma**2) )\n",
    "\n",
    "def GaussianFit2(x, xbar, sigma):\n",
    "    return ( (1./sigma/np.sqrt(2*np.pi)) * np.exp(-0.5*(x - xbar)**2/sigma**2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-condition",
   "metadata": {},
   "source": [
    "Define stuff thats gonna be used over and over again.  Check and make sure this stuff gives what I think it gives.  For `PtResponseCounts`, remember that its two dimensional; different counts for each eta bin and pt bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "EtaBins = output['r_pt_ptveta'].axis('eta')\n",
    "EtaBinNums = len(output['eta'].values()[('QCDFlat',)])\n",
    "EtaCounts = output['eta'].values()[('QCDFlat',)]\n",
    "\n",
    "PtBins = output['r_pt_ptveta'].axis('pt')\n",
    "PtBinNums = len(output['pt'].values()[('QCDFlat',)])\n",
    "PtCounts = output['pt'].values()[('QCDFlat',)]\n",
    "\n",
    "PtResponseBins = output['r_pt_ptveta'].axis('r')\n",
    "PtResponseBinNums = len(output['r_pt_ptveta'].integrate('eta', EtaBins[1]).integrate('pt',PtBins[1]).values()[('QCDFlat',)])\n",
    "def PtResponseCounts(etabin_number, ptbin_number): # takes integer values of bin numbers\n",
    "    Counts = output['r_pt_ptveta'].integrate('eta', EtaBins[etabin_number]).integrate('pt',PtBins[ptbin_number]).values()[('QCDFlat',)]\n",
    "    return Counts\n",
    "\n",
    "# --- yaxis values of histograms for each bin --- #\n",
    "print('# of Eta Bins = ', EtaBinNums)\n",
    "print('# of pT Bins = ', PtBinNums)\n",
    "print('# of Response Bins = ', PtResponseBinNums)\n",
    "print()\n",
    "print('Eta Counts: ', EtaCounts)\n",
    "print('\\npT Counts: ', PtCounts)\n",
    "print('\\nResponse Counts:', PtResponseCounts(7,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-reducing",
   "metadata": {},
   "source": [
    "### List all Bins and Bin Numbers for Future Reference if Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-alpha",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = hist.plotgrid(output['eta'], overlay=\"dataset\", stack=False, density=True)\n",
    "for i in range(EtaBinNums):\n",
    "    print('Bin #' + str(i) + ': '+ str(EtaBins[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-mitchell",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = hist.plotgrid(output['pt'], overlay=\"dataset\", stack=False, density=True)\n",
    "for i in range(PtBinNums):\n",
    "    print('Bin #' + str(i) + ': '+ str(PtBins[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-disposal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(PtResponseBinNums):\n",
    "    print('Bin #' + str(i) + ': '+ str(PtResponseBins[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-simple",
   "metadata": {},
   "source": [
    "# $p_T$ Response for select eta and pt ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-blowing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collect_etaranges = [] # for violin plots later...\n",
    "for bins in EtaBins[1:20]:\n",
    "    choicebin = PtBins[15] # choose a single pt bin\n",
    "    Hists = output['r_pt_ptveta'].sum('dataset').integrate('eta', bins).integrate('pt',choicebin)\n",
    "    collect_etaranges.append(list(Hists.values().values())[0])\n",
    "    title = r'$\\eta$ range ' + str(bins) + r'; $p_T$ range ' + str(choicebin)\n",
    "    ax = hist.plot1d(Hists)\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_ptranges = [] # for violin plots later...\n",
    "for bins in PtBins[2:35]:\n",
    "    choicebin = EtaBins[11] # choose a single eta bin\n",
    "    Hists = output['r_pt_ptveta'].sum('dataset').integrate('eta', choicebin).integrate('pt',bins)\n",
    "    collect_ptranges.append(list(Hists.values().values())[0])\n",
    "    title = r'$\\eta$ range ' + str(choicebin) + r'; $p_T$ range ' + str(bins)\n",
    "    ax = hist.plot1d(Hists)\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-worst",
   "metadata": {},
   "source": [
    "# Loop Over All $p_T$ Responses and Fit the Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "PtResponseBins_array = np.arange(0, 5, 0.025) # PtResponseBins should be an array for the xdata of curve_fit\n",
    "xspace = np.linspace(0, 5, 100000) # Generate more x values if curve is not smooth enough\n",
    "xbar_vals = [] # Store mean values for each eta bin (outer) and pt bin (inner)\n",
    "sigma_vals = [] # Store standard deviation values for each eta bin (outer) and pt bin (inner)\n",
    "\n",
    "for i in range(EtaBinNums):\n",
    "    inner_xbar_array = []\n",
    "    inner_sigma_array = []\n",
    "    for j in range(PtBinNums):\n",
    "        if not (i>0) or not (j>1): # Skip first eta bin, first pt bin and second pt bin to avoid empty histograms\n",
    "            continue\n",
    "        elif j == 35: # Skip last pt bin to avoid empty histograms\n",
    "            continue\n",
    "        else:\n",
    "            Hists = output['r_pt_ptveta'].sum('dataset').integrate('eta', EtaBins[i]).integrate('pt',PtBins[j])\n",
    "        \n",
    "            # --- fit --- #\n",
    "            try:\n",
    "                popt1, pcov1 = sciop.curve_fit(GaussianFit1, xdata=PtResponseBins_array, ydata=PtResponseCounts(i, j), p0=[1., 1., 0.1], bounds=([0.5, 1.0, 0.01], [1.5, 500., 1]))\n",
    "                print('Guassian1 fit param. (mean, amp, stddev) = ', popt1)\n",
    "                xbar, sigma = popt1[0], popt1[2]\n",
    "                inner_xbar_array.append(xbar)\n",
    "                inner_sigma_array.append(sigma)\n",
    "\n",
    "            except RuntimeError:\n",
    "                print('Optimal parameters not found; eta bin ' + str(EtaBins[i]) + '; pt bin ' + str(PtBins[j]) + ' skipped')\n",
    "                inner_xbar_array.append(0)\n",
    "                inner_sigma_array.append(0)\n",
    "                continue\n",
    "\n",
    "            title = r'$\\eta$ range ' + str(EtaBins[i]) + r'; $p_T$ range ' + str(PtBins[j])\n",
    "            ax = hist.plot1d(Hists)\n",
    "            ax.set_title(title)\n",
    "\n",
    "            plt.plot(PtResponseBins_array, GaussianFit1(PtResponseBins_array, *popt1), color='red', linewidth=2.5, label=r'Gaussian 1')\n",
    "            plt.show()\n",
    "        \n",
    "    xbar_vals.append(inner_xbar_array)\n",
    "    sigma_vals.append(inner_sigma_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(xbar_vals)\n",
    "np.array(sigma_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-approach",
   "metadata": {},
   "source": [
    "# 2D $p_T$ Response Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bins in EtaBins:\n",
    "    title = r'$\\eta$ range ' + str(bins)\n",
    "    ax = hist.plot2d(output['r_pt_ptveta'].sum('dataset').integrate('eta', bins),xaxis='pt')\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bins in PtBins:\n",
    "    title = r'$p_T$ range ' + str(bins)\n",
    "    ax = hist.plot2d(output['r_pt_ptveta'].sum('dataset').integrate('pt', bins),xaxis='eta')\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bins in EtaBins:\n",
    "    h = output['r_pt_ptveta'].sum('dataset').integrate('eta', bins)\n",
    "    xaxis='pt'\n",
    "    xaxis = h.axis(xaxis)\n",
    "    yaxis = h.axes()[1]\n",
    "    xoverflow='none'\n",
    "    xedges = xaxis.edges(overflow=xoverflow)\n",
    "    xcenters = xaxis.centers(overflow=xoverflow)\n",
    "    vals = list(h.values().values())\n",
    "\n",
    "    avs = [np.average(h.axes()[1].centers(), weights=b) if np.sum(b)>0 else 0. for b in vals[0]]\n",
    "    #dummy\n",
    "    avs_err = [0.]*len(avs)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    ax.set_xlabel(xaxis.label)\n",
    "    ax.set_ylabel(yaxis.label)\n",
    "    ax.set_xlim(xedges[0], xedges[-1])\n",
    "    ax.set_ylim(0.5, 1.5)\n",
    "\n",
    "    errbar = ax.errorbar(x=xcenters, y=avs, yerr=avs_err)\n",
    "    \n",
    "    title = title = r'$\\eta$ range ' + str(bins)\n",
    "    ax.set_title(title)\n",
    "    plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bins in PtBins:\n",
    "    h = output['r_pt_ptveta'].sum('dataset').integrate('pt', bins)\n",
    "    xaxis='eta'\n",
    "    xaxis = h.axis(xaxis)\n",
    "    yaxis = h.axes()[1]\n",
    "    xoverflow='none'\n",
    "    xedges = xaxis.edges(overflow=xoverflow)\n",
    "    xcenters = xaxis.centers(overflow=xoverflow)\n",
    "    vals = list(h.values().values())\n",
    "\n",
    "    avs = [np.average(h.axes()[1].centers(), weights=b) if np.sum(b)>0 else 0. for b in vals[0]]\n",
    "    #dummy\n",
    "    avs_err = [0.]*len(avs)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    ax.set_xlabel(xaxis.label)\n",
    "    ax.set_ylabel(yaxis.label)\n",
    "    ax.set_xlim(xedges[0], xedges[-1])\n",
    "    ax.set_ylim(0.5, 1.5)\n",
    "\n",
    "    errbar = ax.errorbar(x=xcenters, y=avs, yerr=avs_err)\n",
    "    \n",
    "    title = title = r'$p_T$ range ' + str(bins)\n",
    "    ax.set_title(title)\n",
    "    #plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-laser",
   "metadata": {},
   "source": [
    "Would be awesome to have a kind of projection function that gives \"profile plots\", e.g. \n",
    "* showing arithmetic mean +/- error, \n",
    "* median +/- errror (or interquartile range), \n",
    "* mode (e.g. from a Gaussian fit)\n",
    "* violin plots etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = [PtCounts, EtaCounts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.violinplot(collections, showmedians=False, showmeans=True, showextrema=False)\n",
    "ax.set_xlabel('Outputs')\n",
    "ax.set_ylabel('Counts')\n",
    "ax.set_xticks([1,2])\n",
    "ax.set_xticklabels([r'$p_T$', r'$\\eta$'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Smaller range of collections (fewer violin plots at a time) if you want to see the details of the violin'''\n",
    "a = (collect_ptranges[2], collect_ptranges[3])\n",
    "b = (collect_etaranges[4], collect_etaranges[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.violinplot(a, showmedians=True, showmeans=True, showextrema=True)\n",
    "ax.set_xlabel(r'$p_T$ Bin Number')\n",
    "ax.set_ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.violinplot(collect_etaranges, showmedians=True, showmeans=True, showextrema=True)\n",
    "ax.set_xlabel(r'$\\eta$ Bin Number')\n",
    "ax.set_ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-footwear",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
